<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Using large data files with workflowr • workflowr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Using large data files with workflowr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">workflowr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.7.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/wflow-01-getting-started.html">Getting started</a>
</li>
<li>
  <a href="../articles/wflow-05-faq.html">FAQ</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/workflowr/workflowr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Using large data files with workflowr</h1>
            <h3 data-toc-skip class="subtitle">workflowr version
1.7.2</h3>
                        <h4 data-toc-skip class="author">John
Blischak</h4>
            
            <h4 data-toc-skip class="date">2025-08-02</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/workflowr/workflowr/blob/main/vignettes/wflow-10-data.Rmd" class="external-link"><code>vignettes/wflow-10-data.Rmd</code></a></small>
      <div class="hidden name"><code>wflow-10-data.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Workflowr provides many features to track the progress of your data
analysis project and make it easier to reproduce both the current
version as well as previous versions of the project. However, this is
only possible if the data files from previous versions can also be
restored. In other words, even if you can obtain the code from six
months ago, if you can’t obtain the data from six months ago, you won’t
be able to reproduce your previous analysis.</p>
<p>Unfortunately, if you have large data files, you can’t simply commit
them to the Git repository along with the code. The max file size able
to be pushed to GitHub is <a href="https://help.github.com/en/github/managing-large-files/conditions-for-large-files" class="external-link">100
MB</a>, and this is in general a good practice to follow no matter what
Git hosting service you are using. Large files will make each push and
pull take much longer and increase the risk of the download timing out.
This vignette discusses various strategies for versioning your large
data files.</p>
</div>
<div class="section level2">
<h2 id="option-0-reconsider-versioning-your-large-data-files">Option 0: Reconsider versioning your large data files<a class="anchor" aria-label="anchor" href="#option-0-reconsider-versioning-your-large-data-files"></a>
</h2>
<p>Before considering any of the options below, you need to reconsider
if this is even necessary for your project. And if it is, which data
files need to be versioned. Specifically, large raw data files that are
never modified do not need to be versioned. Instead, you could follow
these steps:</p>
<ol style="list-style-type: decimal">
<li>Upload the files to an online data repository, a private FTP server,
etc.</li>
<li>Add a script to your workflowr project that can download all the
files</li>
<li>Include the instructions in your README and your workflowr website
that explain how to download the files</li>
</ol>
<p>For example, an <a href="https://en.wikipedia.org/wiki/RNA-Seq" class="external-link">RNA
sequencing</a> project will produce <a href="https://en.wikipedia.org/wiki/FASTQ_format" class="external-link">FASTQ</a> files that
are large and won’t be modified. Instead of committing these files to
the Git repository, they should instead be uploaded to <a href="https://www.ncbi.nlm.nih.gov/geo/" class="external-link">GEO</a>/<a href="https://www.ncbi.nlm.nih.gov/sra" class="external-link">SRA</a>.</p>
</div>
<div class="section level2">
<h2 id="option-1-record-metadata">Option 1: Record metadata<a class="anchor" aria-label="anchor" href="#option-1-record-metadata"></a>
</h2>
<p>If your large data files are modified throughout the project, one
option would be to record metadata about the data files, save it in a
plain text file, and then commit the plain text file to the Git
repository. For example, you could record the modification date, file
size, <a href="https://en.wikipedia.org/wiki/MD5" class="external-link">MD5 checksum</a>,
number of rows, number of columns, column means, etc.</p>
<p>For example, if your data file contains observational measurements
from a remote sensor, you could record the date of the last observation
and commit this information. Then if you need to reproduce an analysis
from six months ago, you could recreate the previous version of the data
file by filtering on the date column.</p>
</div>
<div class="section level2">
<h2 id="option-2-use-git-lfs-large-file-storage">Option 2: Use Git LFS (Large File Storage)<a class="anchor" aria-label="anchor" href="#option-2-use-git-lfs-large-file-storage"></a>
</h2>
<p>If you are comfortable using Git in the terminal, a good option is <a href="https://git-lfs.com/" class="external-link">Git LFS</a>. It is an extension to Git that
adds extra functionality to the standard Git commands. Thus it is
completely compatible with workflowr.</p>
<p>Instead of committing the large file to the Git repository, it
instead commits a plain text file containing a unique hash. It then
uploads the large file to a remote server. If you checkout a previous
version of the code, it will use the unique hash in the file to download
the previous version of the large data file from the server.</p>
<p>Git LFS is <a href="https://help.github.com/en/github/managing-large-files/about-storage-and-bandwidth-usage" class="external-link">integrated
into GitHub</a>. However, a free account is only allotted 1 GB of free
storage and 1 GB a month of free bandwidth. Thus you may have to upgrade
to a paid GitHub account if you need to version lots of large data
files.</p>
<p>See the <a href="https://git-lfs.com/" class="external-link">Git LFS</a> website to
download the software and set it up to track your large data files.</p>
<p>Note that for workflowr you can’t use Git LFS with any of the website
files in <code>docs/</code>. <a href="https://pages.github.com/" class="external-link">GitHub
Pages</a> serves the website using the exact versions of the files in
that directory on GitHub. In other words, it won’t pull the large data
files from the LFS server. Therefore everything will look fine on your
local machine, but break once pushed to GitHub.</p>
<p>As an example of a workflowr project that uses Git LFS, see the
GitHub repository <a href="https://github.com/jdblischak/singlecell-qtl" class="external-link">singlecell-qtl</a>.
Note that the large data files, e.g. <a href="https://github.com/jdblischak/singlecell-qtl/blob/master/data/eset/02192018.rds" class="external-link"><code>data/eset/02192018.rds</code></a>
, contain the phrase “Stored with Git LFS”. If you download the
repository with <code>git clone</code>, the large data files will only
contain the unique hashes. See the <a href="https://jdblischak.github.io/singlecell-qtl/contributing.html" class="external-link">contributing
instructions</a> for how to use Git LFS to download the latest version
of the large data files.</p>
</div>
<div class="section level2">
<h2 id="option-3-use-piggyback">Option 3: Use piggyback<a class="anchor" aria-label="anchor" href="#option-3-use-piggyback"></a>
</h2>
<p>An alternative option to Git LFS is the R package <a href="https://cran.r-project.org/package=piggyback" class="external-link">piggyback</a>. Its
main advantages are that it doesn’t require paying to upgrade your
GitHub account or configuring Git. Instead, it uses R functions to
upload large data files to <a href="https://help.github.com/en/github/administering-a-repository/about-releases" class="external-link">releases</a>
on your GitHub repository. The main disadvantage, especially for
workflowr, is that it isn’t integrated with Git. Therefore you will have
to manually version the large data files by uploading them via
piggyback, and recording the release version in a file in the workflowr
project. This option is recommended if you anticipate substantial, but
infrequent, changes to your large data files.</p>
</div>
<div class="section level2">
<h2 id="option-4-use-a-database">Option 4: Use a database<a class="anchor" aria-label="anchor" href="#option-4-use-a-database"></a>
</h2>
<p>Importing large amounts of data into an R session can drastically
degrade R’s performance or even cause it to crash. If you have a large
amount of data stored in one or more tabular files, but only need to
access a subset at a time, you should consider converting your large
data files into a single database. Then you can query the database from
R to obtain a given subset of the data needed for a particular analysis.
Not only is this memory efficient, but you will benefit from the
improved organization of your project’s data. See the CRAN Task View on
<a href="https://cran.r-project.org/view=Databases" class="external-link">Databases</a> for
resources for interacting with databases with R.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by John Blischak, Peter Carbonetto, Matthew Stephens.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

      </footer>
</div>






  </body>
</html>
