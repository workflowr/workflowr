<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Using large data files with workflowr • workflowr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Using large data files with workflowr">
<meta property="og:description" content="workflowr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">workflowr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.7.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/wflow-01-getting-started.html">Getting started</a>
</li>
<li>
  <a href="../articles/wflow-05-faq.html">FAQ</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/workflowr/workflowr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Using large data files with workflowr</h1>
            <h3 data-toc-skip class="subtitle">workflowr version 1.7.0</h3>
                        <h4 data-toc-skip class="author">John Blischak</h4>
            
            <h4 data-toc-skip class="date">2021-12-21</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/workflowr/workflowr/blob/HEAD/vignettes/wflow-10-data.Rmd" class="external-link"><code>vignettes/wflow-10-data.Rmd</code></a></small>
      <div class="hidden name"><code>wflow-10-data.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Workflowr provides many features to track the progress of your data analysis project and make it easier to reproduce both the current version as well as previous versions of the project. However, this is only possible if the data files from previous versions can also be restored. In other words, even if you can obtain the code from six months ago, if you can’t obtain the data from six months ago, you won’t be able to reproduce your previous analysis.</p>
<p>Unfortunately, if you have large data files, you can’t simply commit them to the Git repository along with the code. The max file size able to be pushed to GitHub is <a href="https://help.github.com/en/github/managing-large-files/conditions-for-large-files" class="external-link">100 MB</a>, and this is in general a good practice to follow no matter what Git hosting service you are using. Large files will make each push and pull take much longer and increase the risk of the download timing out. This vignette discusses various strategies for versioning your large data files.</p>
</div>
<div class="section level2">
<h2 id="option-0-reconsider-versioning-your-large-data-files">Option 0: Reconsider versioning your large data files<a class="anchor" aria-label="anchor" href="#option-0-reconsider-versioning-your-large-data-files"></a>
</h2>
<p>Before considering any of the options below, you need to reconsider if this is even necessary for your project. And if it is, which data files need to be versioned. Specifically, large raw data files that are never modified do not need to be versioned. Instead, you could follow these steps:</p>
<ol style="list-style-type: decimal">
<li>Upload the files to an online data repository, a private FTP server, etc.</li>
<li>Add a script to your workflowr project that can download all the files</li>
<li>Include the instructions in your README and your workflowr website that explain how to download the files</li>
</ol>
<p>For example, an <a href="https://en.wikipedia.org/wiki/RNA-Seq" class="external-link">RNA sequencing</a> project will produce <a href="https://en.wikipedia.org/wiki/FASTQ_format" class="external-link">FASTQ</a> files that are large and won’t be modified. Instead of committing these files to the Git repository, they should instead be uploaded to <a href="https://www.ncbi.nlm.nih.gov/geo/" class="external-link">GEO</a>/<a href="https://www.ncbi.nlm.nih.gov/sra" class="external-link">SRA</a>.</p>
</div>
<div class="section level2">
<h2 id="option-1-record-metadata">Option 1: Record metadata<a class="anchor" aria-label="anchor" href="#option-1-record-metadata"></a>
</h2>
<p>If your large data files are modified throughout the project, one option would be to record metadata about the data files, save it in a plain text file, and then commit the plain text file to the Git repository. For example, you could record the modification date, file size, <a href="https://en.wikipedia.org/wiki/MD5" class="external-link">MD5 checksum</a>, number of rows, number of columns, column means, etc.</p>
<p>For example, if your data file contains observational measurements from a remote sensor, you could record the date of the last observation and commit this information. Then if you need to reproduce an analysis from six months ago, you could recreate the previous version of the data file by filtering on the date column.</p>
</div>
<div class="section level2">
<h2 id="option-2-use-git-lfs-large-file-storage">Option 2: Use Git LFS (Large File Storage)<a class="anchor" aria-label="anchor" href="#option-2-use-git-lfs-large-file-storage"></a>
</h2>
<p>If you are comfortable using Git in the terminal, a good option is <a href="https://git-lfs.github.com/" class="external-link">Git LFS</a>. It is an extension to Git that adds extra functionality to the standard Git commands. Thus it is completely compatible with workflowr.</p>
<p>Instead of committing the large file to the Git repository, it instead commits a plain text file containing a unique hash. It then uploads the large file to a remote server. If you checkout a previous version of the code, it will use the unique hash in the file to download the previous version of the large data file from the server.</p>
<p>Git LFS is <a href="https://help.github.com/en/github/managing-large-files/about-storage-and-bandwidth-usage" class="external-link">integrated into GitHub</a>. However, a free account is only allotted 1 GB of free storage and 1 GB a month of free bandwidth. Thus you may have to upgrade to a paid GitHub account if you need to version lots of large data files.</p>
<p>See the <a href="https://git-lfs.github.com/" class="external-link">Git LFS</a> website to download the software and set it up to track your large data files.</p>
<p>Note that for workflowr you can’t use Git LFS with any of the website files in <code>docs/</code>. <a href="https://pages.github.com/" class="external-link">GitHub Pages</a> serves the website using the exact versions of the files in that directory on GitHub. In other words, it won’t pull the large data files from the LFS server. Therefore everything will look fine on your local machine, but break once pushed to GitHub.</p>
<p>As an example of a workflowr project that uses Git LFS, see the GitHub repository <a href="https://github.com/jdblischak/singlecell-qtl" class="external-link">singlecell-qtl</a>. Note that the large data files, e.g. <a href="https://github.com/jdblischak/singlecell-qtl/blob/master/data/eset/02192018.rds" class="external-link"><code>data/eset/02192018.rds</code></a> , contain the phrase “Stored with Git LFS”. If you download the repository with <code>git clone</code>, the large data files will only contain the unique hashes. See the <a href="https://jdblischak.github.io/singlecell-qtl/contributing.html" class="external-link">contributing instructions</a> for how to use Git LFS to download the latest version of the large data files.</p>
</div>
<div class="section level2">
<h2 id="option-3-use-piggyback">Option 3: Use piggyback<a class="anchor" aria-label="anchor" href="#option-3-use-piggyback"></a>
</h2>
<p>An alternative option to Git LFS is the R package <a href="https://cran.r-project.org/package=piggyback" class="external-link">piggyback</a>. Its main advantages are that it doesn’t require paying to upgrade your GitHub account or configuring Git. Instead, it uses R functions to upload large data files to <a href="https://help.github.com/en/github/administering-a-repository/about-releases" class="external-link">releases</a> on your GitHub repository. The main disadvantage, especially for workflowr, is that it isn’t integrated with Git. Therefore you will have to manually version the large data files by uploading them via piggyback, and recording the release version in a file in the workflowr project. This option is recommended if you anticipate substantial, but infrequent, changes to your large data files.</p>
</div>
<div class="section level2">
<h2 id="option-4-use-a-database">Option 4: Use a database<a class="anchor" aria-label="anchor" href="#option-4-use-a-database"></a>
</h2>
<p>Importing large amounts of data into an R session can drastically degrade R’s performance or even cause it to crash. If you have a large amount of data stored in one or more tabular files, but only need to access a subset at a time, you should consider converting your large data files into a single database. Then you can query the database from R to obtain a given subset of the data needed for a particular analysis. Not only is this memory efficient, but you will benefit from the improved organization of your project’s data. See the CRAN Task View on <a href="https://cran.r-project.org/view=Databases" class="external-link">Databases</a> for resources for interacting with databases with R.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by John Blischak, Peter Carbonetto, Matthew Stephens.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.1.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
